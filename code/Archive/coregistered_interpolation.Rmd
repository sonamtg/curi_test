---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r, message = FALSE}
library(tidyverse)
library(raster)
library(terra)
library(viridis)
library(RColorBrewer)
library(sf)
library(tibble)
library(tidymodels)
library(caret)
library(stats)
```

```{r}
stor_no_outliers <- read_csv("data/stor_no_outliers.csv")
stor_cor_df <- read_csv("data/stor_cor_df.csv")
```

#Setting out a dataset for making a polynomial model, then selecting it for us to use to interpolate (filling in for missing data)

```{r}
elev_bins_med <- stor_no_outliers %>% 
  group_by(elev_cut) %>% 
  summarise(med_elev_diff = median(elev_diff),
            count = n()) %>% 
  mutate(lower = as.numeric(gsub("\\((.*),.*\\]", "\\1", elev_cut)),
         upper = as.numeric(gsub(".*,(.*)\\]", "\\1", elev_cut)),
         med_elev_cut = (lower + upper) / 2,
         mmed = median(med_elev_cut)) %>% 
  mutate(cen_elev_med = med_elev_cut - 1475) #1475

elev_bins_med %>% 
  ggplot(aes(x = cen_elev_med, y = med_elev_diff)) +
  geom_point()

```


```{r}
# weighted
poly_1 <- lm(med_elev_diff ~ cen_elev_med, data = elev_bins_med, weights = count)
summary(poly_1)
```

```{r}
poly_2 <- lm(med_elev_diff ~ cen_elev_med + I(cen_elev_med ^ 2), data = elev_bins_med, weights = count)
summary(poly_2)

```

```{r}
poly_3 <- lm(med_elev_diff ~ cen_elev_med + I(cen_elev_med ^ 2) + I(cen_elev_med ^ 3), data = elev_bins_med, weights = count)
summary(poly_3)
```
 
# From the plot below, you can see that the 3rd degree model is better than all the others
```{r}
elev_bins_med %>% 
  ggplot() +
  geom_point(aes(x = cen_elev_med, y = med_elev_diff), color = "brown") + 
  geom_function(fun = function(cen_elev_med) predict(poly_1, newdata = data.frame(cen_elev_med = cen_elev_med)), aes(color = "1st Degree")) + 
  geom_function(fun = function(cen_elev_med) predict(poly_2, newdata = data.frame(cen_elev_med = cen_elev_med)), aes(color = "2nd Degree")) + 
  geom_function(fun = function(cen_elev_med) predict(poly_3, newdata = data.frame(cen_elev_med = cen_elev_med)), aes(color = "3rd Degree")) +
  geom_smooth(aes(x = cen_elev_med, y = med_elev_diff, color = "Original"), linetype = 2, color = "black", se = FALSE) +
  scale_color_manual(values = c("red", "blue", "green"), 
                     labels = c("1st Degree", "2nd Degree", "3rd Degree")) +
  labs(x = "Cen_Elev_Med", y = "Med_Elev_Diff", title = "Model Comparison") 
```
 

identifying the void pixels and predicting diff
```{r}
interpolated_stor <- stor_cor_df %>% 
  filter(is.glacier == 1) %>% 
  mutate(cen_elev_med = elev - 1475) %>% 
  mutate(pred_elev_diff = (ifelse(is.na(elev_diff), predict(poly_3, newdata = interpolated_stor), elev_diff)),
         predicted = ifelse(is.na(elev_diff), TRUE, FALSE)) 
```

#calculating the total vol change, but subject to change
```{r}
interpolated_stor %>% 
  summarise(total_vol_chg = sum(pred_elev_diff) * 4/1000^3, med_elev_diff = median(pred_elev_diff)) #  -0.00783 km^3
```


```{r}
fill_raster <- interpolated_stor %>% 
  dplyr::select(x, y, elev_diff) %>% 
  rasterFromXYZ()
```

#Checking to see if the interpolation worked (which it did), and to see if it made sense
```{r}
plot(fill_raster, col = magma(10), zlim = c(-20,20))
plot(fill_raster, col = rwb, zlim = c(-20,20))
plot(storglacier, add = TRUE) #zoom in on the missing data region to see how it looks
#compare this to the lidar for the void location
```



```{r}
write_csv(interpolated_stor, "data/interpolated_stor.csv") 
```

#Next RMD is CV_Rolstad_MedianModel2.rmd
